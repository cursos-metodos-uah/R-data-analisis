---
title: "Práctico 3. Operacionalización de variables (segunda parte)"
subtitle: "R data analisis"
linktitle: "Práctico 3: Operacionalización"
date: "2024-03-18"
lang: es
---

# Presentación

## Objetivo de la práctica

El desarrollo de esta guía tiene por objetivo revisar algunos procedimientos básicos de la preparación de datos con R, que son necesarios para luego poder analizar e interpretar los datos.

Por temas de orden y reproducibilidad, en este curso vamos a separar en **dos momentos** el trabajo con datos, y dos archivos de código correspondientes:

  - **Preparación** corresponde a lo que se conoce generalmente como "limpieza", es decir, realizar las modificaciones necesarias para poder efectuar los análisis. Estas modificaciones previas al análisis son necesarias ya que los datos originales con los que se va a trabajar en general no vienen perfectamente adaptados a los análisis que se quieren hacer. Por lo tanto, en cuanto a datos también hacemos la distinción entre datos originales y datos preparados (o procesados).

  - **Análisis**: se relaciona tanto con análisis descriptivos asociados a las preguntas de investigación y como también modelamiento de datos para contrastar hipótesis de investigación.

#### Los procesos de preparación y análisis vinculados a datos y resultados se presentan en el siguiente esquema:{#flujo}

![](images/produccion.png)

Tanto la preparación como el análisis (que son parte del concepto más general de procesamiento) quedan registrados cada uno en un _archivo de código_.

<span class="sidenote">**Archivo de código R**: archivo con extensión .R donde se almacena el código de análisis. Para generarlo desde RStudio: _File > New File > R Script_ (o ctrl+shift+N), y para grabarlo  _File > Save (o ctrl+s)_, y darle nombre la primera vez (recordar: sin tilde ni ñ, y evitar espacios) </span>

El documento de **código de preparación** posee 5 partes, más una sección de identificación inicial:

0. Identificación y descripción general: Título, autor(es), fecha, información breve sobre el contenido del documento
1. Librerías: cargar librerías a utilizar
2. Datos: carga de datos
3. Selección de variables a utilizar
4. Procesamiento de variables: en este punto, por cada variable se realiza lo siguiente:
    a. Descriptivo básico
    b. Recodificación: datos perdidos y valores (en caso de ser necesario)
    c. Etiquetamiento: de variable y valores (en caso de ser necesario)
    e. Otros ajustes


5. Generación de base de datos preparada para el análisis.

**De rutas, estructura de carpetas y otros **

- **Encontrando la ruta a carpeta local**: lo más fácil es crear la carpeta donde se desean guardar los datos desde el administrador de archivos del computador. Luego, posicionarse con el cursor sobre la carpeta y seleccionar "Propiedades", en la ventana emergente debería aparecer la ruta hacia la carpeta en "Ubicación". Copiar esa ruta y agregar al final el nombre de la carpeta (separada por slash)

- **Sobre los "slashes" (`\` o `/`)**: en la ruta las carpetas y el archivo final aparecen separados por slashes, que según el sistema utilizado pueden ser _slash_ (`/`) o _backslash_ (`\`). En R por defecto se usa _slash_, pero en Windows _backslash_, por lo que si se usa Windows hay que reemplazarlos por _backslash_ o también puede ser por un doble _slash_ (`//`).

- Por temas de compatibilidad general, en las rutas se recomienda evitar tildes, eñes, espacios, mayúsculas y guiones bajos (_).

- **Estructura de carpetas**: para mantener el orden se sugiere seguir un protocolo de estructura de carpetas de proyecto, para lo que recomendamos el protocolo [IPO](https://lisa-coes.com/ipo-protocol/), y que se adapta al flujo de trabajo presentado anteriormente. Básicamente son tres carpetas: **input**, **procesamiento**, **output**. En la carpeta input crear la subcarpeta data-orig para guardar datos originales, y data-proc para los procesados. En procesamiento se guardan los archivos de código y en output las tablas y los gráficos.

![](../files/img/ipo-hex.png)

## Rproject

Un Rproject es una herramienta de R que nos permite establecer un directorio de trabajo en una carpeta de nuestro computador. Al hacerlo, establecemos un espacio de trabajo que permite crear una estructura de carpetas donde guardar los documentos asociados al proyecto. De esta forma, creamos un conjunto de archivos autocontenidos en un solo lugar que nos permite organizar nuestro trabajo y facilitar la **reproducibilidad**. En las próximas sesiones estableceremos un protocolo de trabajo que permite organizar y armonizar el trabajo: el [protocolo IPO](https://lisa-coes.com/ipo-repro/).

Para crear un Rproject:

1. Abrir Rstudio

2. Seleccionar Archivo -> Nuevo proyecto

![](images/project.png)

3. Seleccionamos la opción de directorio existente

4. Seleccionamos la carpeta donde descargamos nuestro repositorio de Github en el paso anterior

5. Apretamos el botón de crear proyecto


Al final de esta práctica la idea es que cada un_ elabore y entienda su propio documento de preparación de datos.

En el ejemplo vamos a procesar variables de confianza en instituciones políticas y variables de caracterización sociodemográfica utilizando los datos de la encuesta [Latinobarómetro](https://www.latinobarometro.org/lat.jsp).

## Antecedentes de los datos a utilizar

Latinobarómetro es un estudio de opinión pública que aplica anualmente alrededor de 20.000 entrevistas en 18 países de América Latina representando a más de 600 millones de habitantes

  "Los gobiernos latinoamericanos, que venían en declive junto con sus democracias desde inicios de la década de 2010, como reflejan los datos de Latinobarómetro, llegaron a fines de 2018 al annus horribilis con la caída de Nicaragua y Venezuela desde su condición de democracias para entrar en la categoría de autocracias y dictadura. 

  De los hiperpresidentes de la primera década del siglo con altos niveles de crecimiento en todos los países y altos niveles de aprobación, la región pasó en la segunda década a los subpresidentes, con una baja en aprobación de gobierno a la mitad, en menos de 10 años. Este rechazo al desempeño de las elites gobernantes, indica su fracaso a fines de 2019 en varios países de la región." (Latinobarómetro, informe 2021, p. 7)


El presente ejercicio tiene por objetivo el procesar los datos para obtener las variables relevantes para el estudio de la **Confianza en instituciones políticas**, entendida como el grado en que los individuos confian en distintas instituciones políticas a nivel nacional, como el gobierno, la justicia, los partidos políticos, etc. Para ello, junto con variables de confianza, consideraremos también variables de estatus (educación), y variables de caracterización sociodemográfica (sexo y edad).

# Preparación de datos Latinobarómetro 2020

## 1. Librerías principales (de R) a utilizar en el análisis{#librerias}

Como sabemos, la lógica de R es instalar librerías (solo 1 vez, con `install.packages("librería")`), y luego cargarlas cada vez que es necesario usarlas (con `library(librería)`). El problema de esto es que a veces no se sabe claramente qué librerías están instaladas y cuales no, lo que va a arrojar error al cargarlas. Y, como sucede en R, existe una librería para solucionar este problema que se llama `pacman` (package manager). Lo que hace `pacman` es cargar la librería, y si no está instalada, la instala y la carga:


Y en adelante, las librerías se cargan así <span class="sidenote"> pacman::p_load(libreria1,libreria2,libreriaX) </span>:


```{r}
pacman::p_load(dplyr, sjmisc, car, sjlabelled, stargazer, haven)
```


Para esta sesión vamos a utilizar Las librerías que vamos a utilizar son:

- `dplyr`: ajuste general de datos
- `sjmisc`: descripción y exploración de base de datos
- `car`: principalmente la función `recode` para recodificar/agrupar valores de variable
- `stargazer`: para tabla descriptiva


## 2. Cargar base de datos

**Ajustar espacio de trabajo**

Previo a la carga de nuestra base de datos, se recomienda ejecutar los siguientes comandos:

```{r}
rm(list=ls())       # borrar todos los objetos en el espacio de trabajo
options(scipen=999) # valores sin notación científica
```

La función `rm(list=ls())` permite comenzar con un espacio de trabajo (environment) vacío y sin otros objetos. Así también, la función `options(scipen=999)` desactiva la notación científica, es decir, veremos los valores numéricos con todos sus decimales.

**Datos**

Las bases de datos se pueden cargar de un archivo local o en línea. Para este caso utilizaremos un archivo en línea que viene en formato RData: **latinobarometro2020.RData**. <span class="sidenote">**Abrir bases de datos en otros formatos**: Los formatos mas comunes en que se almacenan las bases de datos son .dta (Stata),  .sav (Spss) y RData (R). Para abrir desde R utlilizamos la librería `haven` y sus funciones read_dta y read_sav según corresponda. Ej: `datos <- read_dta("base_casen.dta")`. Recordar antes instalar/cargar la librería: `pacman::p_load(haven)`   </span>

```{r}
#cargamos la base de datos desde internet
load(url("https://github.com/cursos-metodos-uah/r-data-analisis/raw/main/files/data/external_data/latinobarometro_rec.RData"))
```


#### 4.2. Educación

* [`reeduc_1`] = REEDUC.1 Nivel de estudios alcanzado - Entrevistado (recodificado)

_a. Descriptivo_

```{r}
frq(proc_data$reeduc_1)
```

_b. Recodificación_

- Vemos que no hay datos perdidos

- Valores

Para hacer más fácil el análisis, recodificamos en tres categorías (en este caso decisión arbitraria. Se debería tener una razón teórica para recodificar)

```
1.  Analfabeto                                =   Educacion basica    =   1
2   Básica incompleta                         =   Educacion basica    =   1
3.  Básica completa                           =   Educacion basica    =   1
4.  Secundaria, media, técnica incompleta     =   Educacion media     =   2
5.  Secundaria, media, técnica completa       =   Educacion media     =   2
6.  Superior incompleta                       =   Educacion superior  =   3
7.  Superior completa                         =   Educacion superior  =   3

```
```{r}
# recodificacion usando funcion 'recode' de la libreria car
proc_data$reeduc_1 <- car::recode(proc_data$reeduc_1, "c(1,2,3)=1; c(4,5)=2; c(6,7)=3")
```

Comprobar con un nuevo descriptivo:

```{r}
frq(proc_data$reeduc_1)
```

Se observa que los valores coinciden con la recodificación (los casos se acumulan entre las categorías 1 y 3), pero las etiquetas ahora no coinciden; se soluciona en el siguiente paso.

_c. Etiquetado_

Para re-etiquetar valores usamos la función `factor`, de R base. Con esta función aprovechamos de transformar la variable educación en una variable categórica, que es lo que corresponde para una variable ordinal.

```{r}
proc_data$reeduc_1 <- factor(proc_data$reeduc_1,
                             labels = c("Educacion basica", "Educacion media", "Educacion superior"),
                             levels = c(1, 2, 3))
```

Luego renombramos la variable con un nombre más sustantivo

```{r}
proc_data <- rename(proc_data,"educacion"=reeduc_1)
```

Además de cambiar el nombre, queremos cambiar la etiqueta de la variable.

```{r}
get_label(proc_data$educacion)
proc_data$educacion <- set_label(x = proc_data$educacion,label = "Educación")
```


### 4.3. Sexo

* [`sexo`]	=	SEXO Sexo

_a. Descriptivo_

```{r}
frq(proc_data$sexo)
```

_b. Recodificación_

En general esta variable no tiene problemas de casos perdidos ni de etiquetas, pero de todas maneras vamos a hacer un cambio de acuerdo a convenciones en análisis de datos, donde por lo general hombres tienen valor 0 y mujeres 1:

```{r}
proc_data$sexo <- car::recode(proc_data$sexo, "1=0;2=1")
```

_c. Etiquetado_

Y ahora cambiamos las etiquetas de acuerdo a la recodificación anterior:

```{r}
proc_data$sexo <- factor(proc_data$sexo,
            labels=c( "Hombre",
                      "Mujer"),
            levels=c(0,1))
```


También queremos cambiar la etiqueta de la variable.

```{r}
get_label(proc_data$sexo)
proc_data$sexo <- set_label(x = proc_data$sexo,label = "Sexo")
```

Revisar con un nuevo descriptivo:

```{r}
frq(proc_data$sexo)
```

### 4.4 Edad

* [`edad`]	=	EDAD Edad.


_a. Descriptivo_

```{r}
frq(proc_data$edad)
```

_b. Recodificación_: no es necesario en este caso

_c. Etiquetado_

Cambio la etiqueta de la variable.

```{r}
get_label(proc_data$edad)
proc_data$edad <- set_label(x = proc_data$edad,label = "Edad")
```

## 5. Generación de base de datos procesada para el análisis

Antes de guardar la base procesada, revisamos nuevamente todas las variables con una tabla descriptiva general mediante la función `stargazer` (de la librería homónima)

Primero vamos a reformatear el objeto proc_data como base de datos (as.data.frame), paso necesario para que sea reconocido como tal por `stargazer`


```{r}
proc_data <-as.data.frame(proc_data)
stargazer(proc_data, type="text")
```
<div class="alert alert-info">
Si se desea modificar las columnas que aparecen en la tabla se puede ocupar la opción `summary.stat`, donde se pueden especificar:

- "max" maximum
- "mean" mean
- "median" median
- "min" minimum
- "n" number of observations
- "p25" 25th percentile
- "p75" 75th percentile
- "sd" standard deviation

Por ejemplo, si quiero una tabla solo con promedio, n, sd y p75: `stargazer(data, type="text", summary.stat = c("mean", "n", "sd", "p75"))`

</div>

- Guardar base de datos procesada: en carpeta local <span class="sidenote">La ruta hacia su carpeta local si está trabajando en windows debería ser algo como "C:/Users/Lenovo/Clases/y aquí nombre del archivo a grabar</span>

El comando para guardar es `save`:

```{r eval=FALSE}
save(proc_data,file = "[ruta hacia carpeta local en su computador]/ELSOC_ess_merit2016.RData")
```

En este caso, seguimos una estructura de carpetas de datos, separando en una carpeta los datos originales, y en otra (proc) los datos procesados:


```{r eval=FALSE}
save(proc_data,file = "files/data/latinobarometro_proc.RData")
```


## Descriptivos básicos de las variables

Podemos conocer ciertas medidas de tendencia central utilizando algunas funciones de `dplyr`

### Media por grupos

```{r}
proc_data %>% dplyr::group_by(sexo) %>% summarise(mean(conf_inst, na.rm=TRUE))
```

```{r}
proc_data %>% dplyr::group_by(educacion) %>% summarise(mean(conf_inst, na.rm=TRUE))
```

### Representación

```{r}
library(sjPlot)
sjt.xtab(proc_data$educacion, proc_data$conf_inst, encoding = "UTF-8")
```
